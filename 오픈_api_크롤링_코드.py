# -*- coding: utf-8 -*-
"""오픈 API 크롤링 코드

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_aNU7TfkyzxeLp_pWtGrMfc6FQacI6F_

## 오픈 API crawlering

### 공공데이터 호출하고 데이터 뽑기

국토교통부_한국건설기술연구원 상시/수시 교통량 정보조회서비스

https://www.data.go.kr/iim/api/selectAPIAcountView.do
"""

! pip install xmltodict

"""https://wonhwa.tistory.com/9

https://shydev.tistory.com/29

http://daplus.net/python-jsondecodeerror-%EC%98%88%EC%83%81-%EA%B0%92-1-%ED%96%89-1-%EC%97%B4-%EB%AC%B8%EC%9E%90-0/

### 2019 수시 도로유형별 교통량 조회 dtype = 1~3, 5

dtype = 1일때 count = 25296 <br/>
dtype = 2일때 count = 50736 <br/>
dtype = 3일때 count = 57360 <br/>
dtype = 4일때 count =<br/>
dtype = 5일때 count = 17280 <br/>
"""

import pandas as pd
from pandas.io.json import json_normalize
import requests
import pprint
import json

# url 입력 (https 말고 http로 수정)

#count=25296
#pageNo=51
#numOfRows=500

#count=50736
#pageNo=102
#numOfRows=500

#count=57360
#pageNo=115
#numOfRows=500

#

#count=17280
#pageNo=35
#numOfRows=500


dataframe = pd.DataFrame(columns=['spot_id', 'direction', 'hour', 'vehicle_type1', 'vehicle_type2',
       'vehicle_type3', 'vehicle_type4', 'vehicle_type5', 'vehicle_type6',
       'vehicle_type7', 'vehicle_type8', 'vehicle_type9', 'vehicle_type10',
       'vehicle_type11', 'vehicle_type12', 'total_count'])

# list = [0,1,2,3,4,5] 

for i in range(35):
  url = 'http://apis.data.go.kr/1613000/KICTopenAPI/spothcv?serviceKey=LGp4ONLLefBCX516C1Cg%2B6LeQEDqU8iKsXZM9nxG0zPoZ61jkjo9tHIBdJXXoeEzPlJMEqi6SlIvRHYrNU12cA%3D%3D&year=2019&dtype=5&output=json&pageNo={}'.format(i) + '&numOfRows=500&type=json'

  # url 불러오기
  response = requests.get(url) # 신뢰할 수 없는 SSL 인증서로 인해 발생, verify=False 구문 추가

  # 데이터 값 출력해보기
  contents = response.text

  # 문자열을 json으로 변경
  json_ob = json.loads(contents) ## dtype 2에서 여기서 에러뜸

  # 필요한 부분만 추출
  body = json_ob['traffic']

  # 데이터프레임으로 변환
  dataframe_i = json_normalize(body)

  # 데이터프레임 append
  dataframe = dataframe.append(dataframe_i)
  dataframe = dataframe.reset_index(drop=True)

dataframe

dataframe.to_csv('dataframe5.csv',index=False)

dataframe1 = pd.read_csv('dataframe.csv')
dataframe2 = pd.read_csv('dataframe2.csv')
dataframe3 = pd.read_csv('dataframe3.csv')
dataframe5 = pd.read_csv('dataframe5.csv')

"""#### 칼럼 추가"""

dataframe1['dtype'] = 1
dataframe2['dtype'] = 2
dataframe3['dtype'] = 3
dataframe5['dtype'] = 5

dataframe2019 = pd.concat([dataframe1,dataframe2,dataframe3,dataframe5])
dataframe2019 = dataframe2019.reset_index(drop=True)
dataframe2019 # 150672 * 17

dataframe2019.to_csv('dataframe2019.csv',index=False)

# dtype 이나 count를 구해서 pageNo, numOfRows는 수동으로 구해줘야한다.
## 자동으로 해결해주는 반복문 만들기

"""https://blog.naver.com/w00j00ng351/222536536693

https://ko.javascript.info/try-catch

### 2020 수시 도로유형별 교통량 조회 dtype = 1~3, 5

dtype = 1일때 count = 24240 <br/>
dtype = 2일때 count = 50592 <br/>
dtype = 3일때 count = 58224 <br/>
dtype = 4일때 count =<br/>
dtype = 5일때 count = 17472 <br/>
"""

import pandas as pd
from pandas.io.json import json_normalize
import requests
import pprint
import json

# url 입력 (https 말고 http로 수정)

#count=24240
#pageNo=49
#numOfRows=500

#count=50592
#pageNo=102
#numOfRows=500

#count=58224 ~ 할차례
#pageNo=117
#numOfRows=500

#

#count=17472
#pageNo=35
#numOfRows=500


dataframe = pd.DataFrame(columns=['spot_id', 'direction', 'hour', 'vehicle_type1', 'vehicle_type2',
       'vehicle_type3', 'vehicle_type4', 'vehicle_type5', 'vehicle_type6',
       'vehicle_type7', 'vehicle_type8', 'vehicle_type9', 'vehicle_type10',
       'vehicle_type11', 'vehicle_type12', 'total_count'])

# list = [0,1,2,3,4,5] 

for i in range(35):
  url = 'http://apis.data.go.kr/1613000/KICTopenAPI/spothcv?serviceKey=LGp4ONLLefBCX516C1Cg%2B6LeQEDqU8iKsXZM9nxG0zPoZ61jkjo9tHIBdJXXoeEzPlJMEqi6SlIvRHYrNU12cA%3D%3D&year=2020&dtype=5&output=json&pageNo={}'.format(i) + '&numOfRows=500&type=json'

  # url 불러오기
  response = requests.get(url) # 신뢰할 수 없는 SSL 인증서로 인해 발생, verify=False 구문 추가

  # 데이터 값 출력해보기
  contents = response.text

  # 문자열을 json으로 변경
  json_ob = json.loads(contents) ## dtype 2에서 여기서 에러뜸
                                 ## 검색해보고 여러 방법들을 시도 해봤지만 다 fail..
                                 ## 기다리는게 답

  # 필요한 부분만 추출
  body = json_ob['traffic']

  # 데이터프레임으로 변환
  dataframe_i = json_normalize(body)

  # 데이터프레임 append
  dataframe = dataframe.append(dataframe_i)
  dataframe = dataframe.reset_index(drop=True)

"""https://itsmycode.com/jsondecodeerror-expecting-value-line-1-column-1-char-0/"""

dataframe

dataframe.to_csv('dataframe2020(5).csv',index=False)

dataframe1 = pd.read_csv('dataframe2020(1).csv')
dataframe2 = pd.read_csv('dataframe2020(2).csv')
dataframe3 = pd.read_csv('dataframe2020(3).csv')
dataframe5 = pd.read_csv('dataframe2020(5).csv')

"""#### 칼럼 추가"""

dataframe1['dtype'] = 1
dataframe2['dtype'] = 2
dataframe3['dtype'] = 3
dataframe5['dtype'] = 5

dataframe2020 = pd.concat([dataframe1,dataframe2,dataframe3,dataframe5])
dataframe2020 = dataframe2020.reset_index(drop=True)
dataframe2020 # 150528 * 17

dataframe2020.to_csv('dataframe2020.csv',index=False)

"""## 💥

### 2018 수시 도로유형별 교통량 조회 dtype = 1~3, 5

dtype = 1일때 count = 25392 <br/>
dtype = 2일때 count = 52550 <br/>
dtype = 3일때 count = <br/>
dtype = 4일때 count =<br/>
dtype = 5일때 count = <br/>
"""

import pandas as pd
from pandas.io.json import json_normalize
import requests
import pprint
import json

# url 입력 (https 말고 http로 수정)

#count=25392
#pageNo=51
#numOfRows=500

#count=52550
#pageNo=106
#numOfRows=500 ~ 여기할차례

#count=56592
#pageNo=114
#numOfRows=500 


dataframe = pd.DataFrame(columns=['spot_id', 'direction', 'hour', 'vehicle_type1', 'vehicle_type2',
       'vehicle_type3', 'vehicle_type4', 'vehicle_type5', 'vehicle_type6',
       'vehicle_type7', 'vehicle_type8', 'vehicle_type9', 'vehicle_type10',
       'vehicle_type11', 'vehicle_type12', 'total_count'])

# list = [0,1,2,3,4,5] 

for i in range(106):
  url = 'http://apis.data.go.kr/1613000/KICTopenAPI/spothcv?serviceKey=LGp4ONLLefBCX516C1Cg%2B6LeQEDqU8iKsXZM9nxG0zPoZ61jkjo9tHIBdJXXoeEzPlJMEqi6SlIvRHYrNU12cA%3D%3D&year=2018&dtype=2&output=json&pageNo={}'.format(i) + '&numOfRows=500&type=json'

  # url 불러오기
  response = requests.get(url) # 신뢰할 수 없는 SSL 인증서로 인해 발생, verify=False 구문 추가

  # 데이터 값 출력해보기
  contents = response.text

  # 문자열을 json으로 변경
  json_ob = json.loads(contents) ## dtype 2에서 여기서 에러뜸
                                 ## 검색해보고 여러 방법들을 시도 해봤지만 다 fail..
                                 ## 기다리는게 답

  # 필요한 부분만 추출
  body = json_ob['traffic']

  # 데이터프레임으로 변환
  dataframe_i = json_normalize(body)

  # 데이터프레임 append
  dataframe = dataframe.append(dataframe_i)
  dataframe = dataframe.reset_index(drop=True)

"""### 일일 트래픽 초과??

![image.png](data:image/png;base64,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)
"""

dataframe

dataframe.to_csv('dataframe2018(1).csv',index=False)





dataframe1 = pd.read_csv('dataframe2020(1).csv')
dataframe2 = pd.read_csv('dataframe2020(2).csv')
dataframe3 = pd.read_csv('dataframe2020(3).csv')
dataframe5 = pd.read_csv('dataframe2020(5).csv')

"""#### 칼럼 추가"""

dataframe1['dtype'] = 1
dataframe2['dtype'] = 2
dataframe3['dtype'] = 3
dataframe5['dtype'] = 5

dataframe2020 = pd.concat([dataframe1,dataframe2,dataframe3,dataframe5])
dataframe2020 = dataframe2020.reset_index(drop=True)
dataframe2020 # 150528 * 17

dataframe2020.to_csv('dataframe2020.csv',index=False)